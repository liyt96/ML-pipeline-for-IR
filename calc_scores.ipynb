{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from random import randrange\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "stoplist = open('/Users/liyuetian/Documents/College/NEU/CS/CS6200/HW_Data/IR_data/AP_DATA/stoplist.txt')\n",
    "\n",
    "stop_arr = []\n",
    "for line in stoplist:\n",
    "    stop_arr.append(line.strip())\n",
    "stop_arr = stop_arr + ['document', 'discuss', 'report', 'include', 'describe', 'identify', 'cite', 'predict', 'taken']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'85': ['alleg', 'measur', 'corrupt', 'public', 'offici', 'government', 'jurisdict', 'worldwid'], '59': ['type', 'weather', 'event', 'directli', 'caus', 'least', 'fatal', 'locat'], '56': ['prime', 'lend', 'rate', 'actual', 'prime', 'rate', 'move'], '71': ['incurs', 'land', 'air', 'water', 'border', 'area', 'countri', 'militari', 'forc', 'second', 'countri', 'guerrilla', 'group', 'base', 'second', 'countri'], '64': ['event', 'result', 'polit', 'motiv', 'hostag', 'take'], '62': ['militari', 'coup', \"d'etat\", 'attempt', 'success', 'countri'], '93': ['support', 'nation', 'rifl', 'associ', 'nra', 'asset'], '99': ['develop', 'iran', 'contra', 'affair'], '58': ['anticip', 'rail', 'strike', 'ongo', 'rail', 'strike'], '77': ['poach', 'method', 'type', 'wildlif'], '54': ['sign', 'contract', 'preliminari', 'agreement', 'make', 'tent', 'reserv', 'launch', 'commerci', 'satellit'], '87': ['current', 'crimin', 'action', 'offic', 'fail', 'u.', 'financi', 'institut'], '94': ['crime', 'perpetr', 'aid', 'comput'], '100': ['effort', 'non', 'communist', 'industri', 'state', 'regul', 'transfer', 'high', 'tech', 'good', 'technolog', 'undesir', 'nation'], '89': ['exist', 'pend', 'invest', 'opec', 'member', 'state', 'downstream', 'oper'], '61': ['role', 'israel', 'iran', 'contra', 'affair'], '95': ['comput', 'applic', 'crime', 'solv'], '68': ['actual', 'studi', 'unsubstanti', 'concern', 'safeti', 'manufactur', 'employe', 'instal', 'worker', 'fine', 'diamet', 'fiber', 'insul', 'product'], '57': ['mci', 'bell', 'system', 'breakup'], '97': ['instanc', 'fiber', 'optic', 'technolog', 'actual'], '98': ['individu', 'organ', 'produc', 'fiber', 'optic', 'equip'], '60': ['side', 'controversi', 'standard', 'perform', 'determin', 'salari', 'level', 'incent', 'pai', 'contrast', 'determin', 'pai', 'sole', 'basi', 'senior', 'longev', 'job'], '80': ['platform', '1988', 'presidenti', 'candid'], '63': ['machin', 'translat', 'system'], '91': ['acquisit', 'u.', 'armi', 'specifi', 'advanc', 'weapon', 'system']}\n"
     ]
    }
   ],
   "source": [
    "querylist = open('/Users/liyuetian/Documents/College/NEU/CS/CS6200/HW_Data/IR_data/AP_DATA/query_desc.51-100.short.txt')\n",
    "query_dict = {}\n",
    "word_arr = []\n",
    "query_arr = []\n",
    "\n",
    "for line in querylist:\n",
    "    if line.strip() != '':\n",
    "        queryno = re.sub('[^A-Za-z0-9]+', '', line.split()[0])\n",
    "        \n",
    "        modified = line[line.find(\".\")+1:]\n",
    "        terms = es.indices.analyze(index='hw6', body={'analyzer': 'stopped', 'text': modified})\n",
    "        for term in terms['tokens']:\n",
    "            query_arr.append(term['token'])\n",
    "        for word in query_arr:\n",
    "            if word not in stop_arr:\n",
    "                word_arr.append(word)\n",
    "        query_dict[queryno] = word_arr\n",
    "        word_arr = []\n",
    "        query_arr = []\n",
    "print(query_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_train_test():\n",
    "    test_set = set()\n",
    "    train_set = set()\n",
    "    while len(test_set) < 5:\n",
    "        test_set.add(randrange(1, 26))\n",
    "    for i in range(1, 26):\n",
    "        if i not in test_set:\n",
    "            train_set.add(i)\n",
    "    qno_map = {1:85, 2:59, 3:56, 4:71, 5:64, 6:62, 7:93, 8:99, 9:58, 10:77, 11:54, 12:87, 13:94, 14:100, 15:89, 16:61, 17:95, 18:68, 19:57, 20:97, 21:98, 22:60, 23:80, 24:63, 25:91}\n",
    "    return [str(qno_map[i]) for i in test_set], [ str(qno_map[i]) for i in train_set ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries, train_queries = get_random_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_dict = {}\n",
    "with open('./info/qrel_dict.txt', 'r') as f:\n",
    "    qrel_dict = json.load(f)\n",
    "    \n",
    "qrel_dict_all = {}\n",
    "with open('./info/qrel_dict_all.txt', 'r') as f:\n",
    "    qrel_dict_all = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_train = {}\n",
    "query_test = {}\n",
    "\n",
    "qrel_train = {}\n",
    "for q in train_queries:\n",
    "    qrel_train[q] = qrel_dict[q]\n",
    "    query_train[q] = query_dict[q]\n",
    "    \n",
    "qrel_test = {}\n",
    "for q in test_queries:\n",
    "    qrel_test[q] = qrel_dict_all[q]\n",
    "    query_test[q] = query_dict[q]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./info/qrel_train.txt', 'w') as f:\n",
    "    json.dump(qrel_train, f)\n",
    "\n",
    "with open('./info/qrel_test.txt', 'w') as f:\n",
    "    json.dump(qrel_test, f)\n",
    "\n",
    "with open('./info/query_train.txt', 'w') as f:\n",
    "    json.dump(query_train, f)\n",
    "\n",
    "with open('./info/query_test.txt', 'w') as f:\n",
    "    json.dump(query_test, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_info = []\n",
    "with open('./info/tf_info.txt', 'r') as f:\n",
    "    tf_info = json.load(f)\n",
    "\n",
    "doc_len_info = {}\n",
    "with open('./info/doc_len_info.txt', 'r') as f:\n",
    "    doc_len_info = json.load(f)\n",
    "\n",
    "def vocab_size():\n",
    "    search_result = es.search(index='ap_data', size=0, body={\n",
    "            \"aggs\" : {\n",
    "                \"unique_terms\" : {\n",
    "                    \"cardinality\" : {\"field\": \"text\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return int(search_result['aggregations']['unique_terms']['value'])\n",
    "\n",
    "voc_size = vocab_size()\n",
    "\n",
    "        \n",
    "def tf_q(queryno, term):\n",
    "    count = Counter(query_dict[queryno])\n",
    "    return count[term]\n",
    "\n",
    "def field_stat():\n",
    "    return es.termvectors(index='ap_data', id='AP890101-0001', fields='text')['term_vectors']['text']['field_statistics']\n",
    "\n",
    "# Get the total number of docs in the corpus\n",
    "total_docs = es.count(index='ap_data')['count']\n",
    "\n",
    "# Get the averge length of th e docs\n",
    "avg_len = field_stat()['sum_ttf'] / total_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okapi_tf(tf, doc_len):\n",
    "    return tf / (tf + 0.5 + 1.5 * (doc_len/avg_len))\n",
    "\n",
    "def tf_idf(tf, doc_len, df, total_docs):\n",
    "    if df == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return okapi_tf(tf, doc_len) * math.log(total_docs / df)\n",
    "\n",
    "def okapi_bm25(tf, tf_q, doc_len, df, k1, k2, b, total_docs, avg_len):\n",
    "    return math.log((total_docs + 0.5) / (df + 0.5)) * \\\n",
    "           ((tf + k1 * tf) / (tf + k1* ((1-b) + b * (doc_len / avg_len)))) * \\\n",
    "           ((tf_q + k2 * tf_q) / (tf_q + k2))\n",
    "\n",
    "def unigram_lm_laplace(tf, doc_len, voc_size):\n",
    "    return math.log((tf + 1) / (doc_len + voc_size))\n",
    "\n",
    "def unigram_lm_jm(tf, doc_len, all_tf, all_len, lmbda):\n",
    "    frntgrd = 0\n",
    "    if doc_len != 0:\n",
    "        frntgrd = float(tf) / doc_len\n",
    "    backgrd = 0\n",
    "    if (all_len - doc_len) != 0:\n",
    "        backgrd = float(all_tf - tf) / (all_len - doc_len)\n",
    "    return lmbda * frntgrd + (1 - lmbda) * backgrd\n",
    "\n",
    "def rank_scores(key, scores, out):\n",
    "    sorted_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for j in range(len(scores)):\n",
    "        str = ('{} Q0 {} {} {} Exp'\n",
    "            .format(key, sorted_scores[j][0], j+1, sorted_scores[j][1]))\n",
    "        out.write(str+\"\\n\")\n",
    "    scores.clear()\n",
    "\n",
    "def add_score(docno, model_scores, score):\n",
    "    if docno in model_scores:\n",
    "        model_scores[docno] += score\n",
    "    else:\n",
    "        model_scores[docno] = score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_okapi_tf(query, qrel_dict, out_path):\n",
    "    okapi_tf_out = open(out_path, \"w\")\n",
    "\n",
    "    okapi_tf_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "    for key, words in tqdm(query.items(), position=0, leave=True, desc='Computing Model'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = qrel_dict[key]\n",
    "            for docno in docs:\n",
    "                tf = 0\n",
    "                for item in new_tf_info:\n",
    "                    if item['id'] == docno:\n",
    "                        tf = item['tf']\n",
    "                        break\n",
    "#                 df = len(new_tf_info)\n",
    "#                 qf = tf_q(key, word)\n",
    "                doc_len = doc_len_info[docno]\n",
    "                add_score(docno, okapi_tf_scores, okapi_tf(tf, doc_len))\n",
    "        rank_scores(key, okapi_tf_scores, okapi_tf_out)\n",
    "    okapi_tf_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf_idf(query, qrel_dict, out_path):\n",
    "    tf_idf_out = open(out_path, \"w\")\n",
    "\n",
    "    tf_idf_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "    for key, words in tqdm(query.items(), position=0, leave=True, desc='Computing Models'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = qrel_dict[key]\n",
    "            df = len(new_tf_info)\n",
    "            for docno in docs:\n",
    "                tf = 0\n",
    "                for item in new_tf_info:\n",
    "                    if item['id'] == docno:\n",
    "                        tf = item['tf']\n",
    "                        break\n",
    "#                 qf = tf_q(key, word)\n",
    "                doc_len = doc_len_info[docno]\n",
    "                add_score(docno, tf_idf_scores, tf_idf(tf, doc_len, df, total_docs))\n",
    "        rank_scores(key, tf_idf_scores, tf_idf_out)\n",
    "    tf_idf_out.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bm25(query, qrel_dict, out_path):\n",
    "    okapi_bm25_out = open(out_path, \"w\")\n",
    "\n",
    "    okapi_bm25_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "    for key, words in tqdm(query.items(), position=0, leave=True, desc='Computing Models'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = qrel_dict[key]\n",
    "            df = len(new_tf_info)\n",
    "            for docno in docs:\n",
    "                tf = 0\n",
    "                for item in new_tf_info:\n",
    "                    if item['id'] == docno:\n",
    "                        tf = item['tf']\n",
    "                        break\n",
    "                \n",
    "                qf = tf_q(key, word)\n",
    "                doc_len = doc_len_info[docno]\n",
    "                add_score(docno, okapi_bm25_scores, okapi_bm25(tf, qf, doc_len, df, 1.2, 100, 0.75, total_docs, avg_len))\n",
    "        rank_scores(key, okapi_bm25_scores, okapi_bm25_out)\n",
    "    okapi_bm25_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unigram_laplace(query, qrel_dict, out_path):\n",
    "    laplace_scores = defaultdict(lambda: 0.0)\n",
    "    out = open(out_path, \"w\")\n",
    "#     voc_size = vocab_size()\n",
    "    for key,words in tqdm(query.items(), position=0, leave=True, desc='Computing Unigram LM Laplace Model'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = qrel_dict[key]\n",
    "            for docno in docs:\n",
    "                tf = 0\n",
    "                for item in new_tf_info:\n",
    "                    if item['id'] == docno:\n",
    "                        tf = item['tf']\n",
    "                        break\n",
    "                doc_len = doc_len_info[docno]\n",
    "                score = unigram_lm_laplace(tf, doc_len, voc_size)\n",
    "                add_score(docno, laplace_scores, score)\n",
    "        rank_scores(key, laplace_scores, out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unigram_jm(query, qrel_dict, out_path):\n",
    "    jelinek_scores = defaultdict(lambda: 0.0)\n",
    "    out = open(out_path, \"w\")\n",
    "    lmbda = .7\n",
    "    for key,words in tqdm(query.items(), position=0, leave=True, desc='Computing Unigram LM JM Model'):\n",
    "        for word in words:\n",
    "            new_tf_info = [element for element in tf_info if element['word'] == word]\n",
    "            docs = qrel_dict[key]\n",
    "            all_tf = 0\n",
    "            all_len = 0\n",
    "            for item in new_tf_info:\n",
    "                if item['word'] == word:\n",
    "                    tf = item['tf']\n",
    "                    all_tf = all_tf + tf\n",
    "                    all_len = all_len + doc_len_info[item['id']]\n",
    "            for docno in docs:\n",
    "                tf = 0\n",
    "                for item in new_tf_info:\n",
    "                    if item['id'] == docno:\n",
    "                        tf = item['tf']\n",
    "                        break\n",
    "                doc_len = doc_len_info[docno]\n",
    "                lmbda = .7\n",
    "                score = unigram_lm_jm(tf, doc_len, all_tf, all_len, lmbda)\n",
    "                add_score(docno, jelinek_scores, score)\n",
    "        rank_scores(key, jelinek_scores, out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute training matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Model: 100%|██████████| 20/20 [03:00<00:00,  9.00s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_tf_okapi_tf(query_train, qrel_train, './result/okapi_tf_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Models: 100%|██████████| 20/20 [02:06<00:00,  6.34s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_tf_idf(query_train, qrel_train, './result/tf_idf_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Models: 100%|██████████| 20/20 [03:23<00:00, 10.15s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_bm25(query_train, qrel_train, './result/bm25_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Unigram LM Laplace Model: 100%|██████████| 20/20 [02:22<00:00,  7.14s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_unigram_laplace(query_train, qrel_train, './result/unigram_laplace_train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Unigram LM JM Model: 100%|██████████| 20/20 [02:06<00:00,  6.34s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_unigram_jm(query_train, qrel_train, './result/unigram_jm_train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute testing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Model: 100%|██████████| 5/5 [31:29<00:00, 377.98s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_tf_okapi_tf(query_test, qrel_test, './result/okapi_tf_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Models: 100%|██████████| 5/5 [31:30<00:00, 378.01s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_tf_idf(query_test, qrel_test, './result/tf_idf_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Models: 100%|██████████| 5/5 [32:16<00:00, 387.29s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_bm25(query_test, qrel_test, './result/bm25_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Unigram LM Laplace Model: 100%|██████████| 5/5 [31:29<00:00, 377.89s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_unigram_laplace(query_test, qrel_test, './result/unigram_laplace_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Unigram LM JM Model: 100%|██████████| 5/5 [32:32<00:00, 390.56s/it]\n"
     ]
    }
   ],
   "source": [
    "compute_unigram_jm(query_test, qrel_test, './result/unigram_jm_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
